[
  {
    "objectID": "1752908400",
    "permalink": "/post/%E6%B0%B4%E5%88%A9%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/",
    "title": "æ°´åˆ©ä¸“ä¸šæœ¯è¯­","content": " åæ¨å…¥åº“ï¼šåæ¨å…¥åº“æµé‡å°±æ˜¯ç”¨æ—¶æ®µå†…åº“å®¹å·®æ¨å‡ºä¸€ åœºæ´ªæ°´çš„å®é™…å…¥åº“è¿‡ç¨‹ï¼Œæœ¬æ„æ˜¯è¿˜åŸæ¬¡é™æ°´å½¢æˆçš„æ´ªæ°´ç”±èµ· æ¶¨å³°é¡¶è½å¹³çš„åŸå§‹è¿‡ç¨‹ã€‚ åº“å®¹ï¼šæŒ‡æ°´åº“åœ¨æŸä¸€æ°´ä½ä¸‹å¯å‚¨å­˜çš„æ°´ä½“æ€»ä½“ç§¯ï¼Œé€šå¸¸åˆ†ä¸ºå¤šä¸ªå±‚çº§ï¼š\næ­»åº“å®¹ï¼šæœ€ä½æ°´ä½ä»¥ä¸‹æ— æ³•æ’å‡ºçš„æ°´é‡ï¼ˆç”¨äºæ³¥æ²™æ·¤ç§¯ã€ç”Ÿæ€ç»´æŒç­‰ï¼‰ã€‚ å…´åˆ©åº“å®¹ï¼ˆæœ‰æ•ˆåº“å®¹ï¼‰ï¼šæ­£å¸¸è“„æ°´ä½ä¸æ­»æ°´ä½ä¹‹é—´çš„å®¹ç§¯ï¼Œç”¨äºä¾›æ°´ã€å‘ç”µç­‰æ•ˆç›Šã€‚ é˜²æ´ªåº“å®¹ï¼šè®¾è®¡æ´ªæ°´ä½ä¸æ­£å¸¸è“„æ°´ä½ä¹‹é—´çš„å®¹ç§¯ï¼Œç”¨äºè°ƒè“„æ´ªæ°´ã€‚ æ€»åº“å®¹ï¼šæ ¡æ ¸æ´ªæ°´ä½ä»¥ä¸‹çš„å…¨éƒ¨å®¹ç§¯ï¼Œæ˜¯æ°´åº“è§„æ¨¡çš„é‡è¦æŒ‡æ ‡ï¼ˆå¦‚å¤§ã€ä¸­ã€å°å‹æ°´åº“çš„åˆ’åˆ†ä¾æ®ï¼‰ã€‚ å¾„æµæ·±ï¼šå¾„æµæ·±æ˜¯æŒ‡åœ¨æŸä¸€æ—¶æ®µå†…é€šè¿‡æ²³æµä¸ŠæŒ‡å®šæ–­é¢çš„å¾„æµæ€»é‡ï¼ˆWä»¥m^3è®¡ï¼‰é™¤ä»¥è¯¥æ–­é¢ä»¥ä¸Šçš„æµåŸŸé¢ç§¯ï¼ˆFï¼Œä»¥kmÂ²è®¡ï¼‰æ‰€å¾—çš„å€¼ã€‚è®¡ç®—å…¬å¼ä¸ºï¼š $$ R = \\frac{W , (\\text{mÂ³})}{1000 \\times F , (\\text{km}^2)} $$ â€‹\tWä¸ºå¾„æµæ€»é‡ï¼ˆmÂ³ï¼‰ï¼ŒFä¸ºæµåŸŸé¢ç§¯ï¼ˆkmÂ²ï¼‰ã€‚ è¯¥å…¬å¼é€šè¿‡å•ä½æ¢ç®—å°†ä¸‰ç»´å¾„æµé‡è½¬åŒ–ä¸ºäºŒç»´æ°´æ·±ï¼Œä¾¿äºä¸åŒæµåŸŸé—´çš„æ°´èµ„æºå¯¹æ¯”ã€‚ å¾„æµæ€»é‡ï¼šå¾„æµæ€»é‡æ˜¯æè¿°æ°´æ–‡å¾ªç¯ä¸­æ°´é‡å¹³è¡¡çš„æ ¸å¿ƒç‰©ç†é‡ï¼ŒæŒ‡åœ¨æŒ‡å®šæ—¶æ®µÎ”tå†…é€šè¿‡æ²³æµæŸä¸€æ–­é¢çš„æ¶²æ€æˆ–å›ºæ€æ°´ä½“ç§¯æ€»å’Œã€‚å…¶åŸºæœ¬è®¡ç®—æ–¹æ³•ä¸ºæ—¶æ®µå¹³å‡æµé‡ä¸æ—¶é—´çš„ä¹˜ç§¯ï¼Œå¸¸ç”¨ç«‹æ–¹ç±³ï¼ˆmÂ³ï¼‰ã€äº¿ç«‹æ–¹ç±³ä½œä¸ºåº¦é‡å•ä½ ã€‚æ ¹æ®å¾„æµè·¯å¾„å¯åˆ†ä¸ºåœ°é¢å¾„æµæ€»é‡ä¸åœ°ä¸‹å¾„æµæ€»é‡ä¸¤ç§ç±»å‹ï¼ŒäºŒè€…å…±åŒæ„æˆæµåŸŸæ°´èµ„æºè¯„ä¼°çš„åŸºç¡€å‚æ•° ã€‚è¯¥æŒ‡æ ‡åœ¨æ°´èµ„æºè§„åˆ’ã€é˜²æ´ªå·¥ç¨‹è®¾è®¡åŠç”Ÿæ€ä¿æŠ¤ç­‰é¢†åŸŸå…·æœ‰é‡è¦åº”ç”¨ä»·å€¼ ã€‚ æµåŸŸé¢ç§¯ï¼šåˆç§°æ±‡æ°´é¢ç§¯æˆ–é›†æ°´é¢ç§¯ï¼ŒæµåŸŸåˆ†æ°´çº¿æ‰€åŒ…å›´çš„é¢ç§¯ã€‚æµåŸŸé¢ç§¯å¤§éƒ½å…ˆä»åœ°å½¢å›¾ä¸Šå®šå‡ºåˆ†æ°´çº¿ç”¨æ±‚ç§¯ä»ªæˆ–å…¶å®ƒæ–¹æ³•é‡ç®—æ±‚å¾—ï¼Œè®¡ç®—å•ä½ä¸ºkmÂ²ã€‚ æ±›æœŸï¼šæ±›æœŸæ˜¯æŒ‡ç”±äºå­£èŠ‚æ€§é™æ°´æˆ–å†°é›ªèåŒ–å¼•èµ·çš„æ±Ÿæ²³æ°´ä½ä¸Šæ¶¨çš„æ—¶æœŸã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå—æ–¹åœ°åŒºçš„æ±›æœŸé€šå¸¸ä¸º4æœˆè‡³10æœˆï¼Œè€ŒåŒ—æ–¹åœ°åŒºçš„æ±›æœŸä¸€èˆ¬ä¸º6æœˆè‡³9æœˆã€‚åœ¨å—æ–¹ï¼Œæ±›æœŸçš„ä¸»æ±›æœŸé€šå¸¸ä»6æœˆ1æ—¥å¼€å§‹ã€‚æ±›æœŸå¹¶ä¸ç­‰åŒäºæ°´ç¾ï¼Œä½†æ°´ç¾é€šå¸¸å‘ç”Ÿåœ¨æ±›æœŸå†…\næ¢…æ±›æœŸï¼šæ¢…æ±›æœŸæ˜¯æŒ‡ç”±æ¢…é›¨æœŸé™æ°´è€Œå¼•èµ·çš„æ±Ÿæ²³æ°´ä½ä¸Šæ¶¨æ—¶æœŸã€‚æ¯å¹´æ—¶é—´ä¸å›ºå®šï¼Œä¸€èˆ¬å‘ç”Ÿåœ¨6æœˆä¸Šæ—¬è‡³7æœˆä¸Šæ—¬ã€‚è¿™æ˜¯æˆ‘å›½é•¿æ±ŸæµåŸŸã€æ·®æ²³æµåŸŸä¸»è¦çš„æ±›æœŸï¼Œæ˜¯ä¸€å¹´ä¸­æµé‡æœ€å¤§çš„æ—¶æœŸï¼Œå®¹æ˜“å¼•èµ·ç¾å®³ã€‚ å°æ±›æœŸï¼š**å°æ±›æœŸæ˜¯æŒ‡æ¯å¹´å°é£å½±å“çš„æ—¶æ®µï¼Œé€šå¸¸ä»5æœˆæŒç»­åˆ°10æœˆï¼Œå…¶ä¸­7æœˆè‡³9æœˆæœ€ä¸ºé¢‘ç¹ã€‚**ç”±äºå°é£çš„å½±å“è€Œå¯¼è‡´çš„æ±›æœŸï¼Œä¸»è¦è¡¨ç°ä¸ºå¼ºé™é›¨å’Œæ´ªæ°´çš„å‘ç”Ÿã€‚å°é£é€šå¸¸åœ¨çƒ­å¸¦åœ°åŒºå½¢æˆï¼Œå¸¦æ¥å¼ºé£å’Œæš´é›¨ï¼Œå¯¹æ²¿æµ·åŠå†…é™†åœ°åŒºé€  â€¦","date": "2025-07-19 00:00:00",
    "updated": "2025-07-19 00:00:00"
  }, 
  {
    "objectID": "1751007600",
    "permalink": "/post/1.-mysql-%E9%85%8D%E7%BD%AE/",
    "title": "Maxwell å’Œ MySQL é…ç½®ç¤ºä¾‹","content": " 1. MySQL é…ç½® ç¼–è¾‘ MySQL é…ç½®æ–‡ä»¶ï¼ˆå¦‚ /etc/my.cnf æˆ– /usr/local/mysql/my.cnfï¼‰ï¼Œç¡®ä¿ä»¥ä¸‹é…ç½®ï¼š\n[mysqld] # åŸºç¡€è®¾ç½® datadir=/usr/local/mysql/data port=3306 max_connections=400 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES lower_case_table_names=1 innodb_file_per_table=1 # binlog é…ç½® server-id=1 # æ¯ä¸ªå®ä¾‹å”¯ä¸€ log-bin=mysql-bin # å¯ç”¨ binlog å¹¶è®¾ç½®åŸºæœ¬åç§° binlog_format=row # è®¾ç½® binlog æ ¼å¼ä¸º ROW expire_logs_days=7 # binlog æ–‡ä»¶ä¿ç•™ 7 å¤©åè‡ªåŠ¨æ¸…ç† binlog_do_db=shtd_db1 # ä»…è®°å½•æŒ‡å®šæ•°æ®åº“çš„ binlog # å¦‚æœæœ‰å¤šä¸ªæ•°æ®åº“ï¼Œå¯ä»¥é‡å¤æ·»åŠ  binlog-do-db è¡Œ # binlog-do-db=shtd_db2 2. åˆ›å»º Maxwell ç”¨æˆ· åœ¨ MySQL ä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œä¸º Maxwell åˆ›å»ºä¸€ä¸ªç”¨æˆ·å¹¶æˆäºˆå¿…è¦æƒé™ï¼š\nCREATE USER \u0026#39;maxwell\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;password\u0026#39;; GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO \u0026#39;maxwell\u0026#39;@\u0026#39;%\u0026#39;; FLUSH PRIVILEGES; 3. Maxwell é…ç½® Maxwell çš„é…ç½®æ–‡ä»¶ï¼ˆå¦‚ config.propertiesï¼‰é€šå¸¸ä½äº Maxwell å®‰è£…ç›®å½•ä¸­ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œéœ€è¦åˆ›å»ºã€‚ä»¥ä¸‹æ˜¯ä¼˜åŒ–åçš„é…ç½®ç¤ºä¾‹ï¼š\n# MySQL é…ç½® host=192.168.1.100 # MySQL ä¸»æœºåœ°å€ user=maxwell # Maxwell ç”¨æˆ· password=password # Maxwell ç”¨æˆ·å¯†ç  port=3306 # MySQL ç«¯å£ # Kafka é…ç½® producer=kafka # æŒ‡å®šæ¶ˆæ¯æŠ•é€’åˆ° Kafka kafka.bootstrap.servers=192.168.1.200:9092,192.168.1.201:9092 # Kafka é›†ç¾¤åœ°å€ kafka_topic=maxwell_shtd_db1 # Kafka Topic åç§° 4. å¯åŠ¨ä¸éªŒè¯ å¯åŠ¨ Maxwell è¿è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨ Maxwellï¼š\nbin/maxwell --config config.properties éªŒè¯æ—¥å¿— è§‚å¯Ÿ Maxwell çš„å¯åŠ¨æ—¥å¿—ï¼Œç¡®è®¤æ˜¯å¦æˆåŠŸè¿æ¥åˆ° MySQL å’Œ Kafkaï¼Œå¹¶è¾“å‡ºç±»ä¼¼ä»¥ä¸‹ä¿¡æ¯ï¼š\nINFO Connected to MySQL at 192.168.1.100:3306 INFO Kafka producer connected to: 192.168.1.200:9092 INFO Starting to stream changes from binlog mysql-bin.000001:154 éªŒè¯ Kafka æ¶ˆæ¯ ä½¿ç”¨ Kafka è‡ªå¸¦çš„æ¶ˆè´¹è€…å·¥å…·æŸ¥çœ‹æŒ‡å®š Topic æ˜¯å¦æ¥æ”¶åˆ° Maxwell å‘é€çš„æ¶ˆæ¯ï¼š\nkafka-console-consumer --bootstrap-server 192.168.1.200:9092 --topic maxwell_shtd_db1 --from-beginning ä½ åº”è¯¥èƒ½çœ‹åˆ°ç±»ä¼¼ä»¥ä¸‹æ ¼å¼çš„ JSON æ¶ˆæ¯ï¼š\n{ \u0026#34;database\u0026#34;: \u0026#34;shtd_db1\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;insert\u0026#34;, \u0026#34;ts\u0026#34;: 1672394546, \u0026#34;xid\u0026#34;: 12345, \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;alice@example.com\u0026#34; } } æ€»ç»“ MySQL é…ç½®ï¼šå¯ç”¨ binlogï¼Œè®¾ç½® row æ ¼å¼ï¼Œæ˜ç¡® binlog è®°å½•çš„æ•°æ®åº“ã€‚ Maxwell é…ç½®ï¼šç¡®ä¿ Kafka åœ°å€æ­£ç¡®ï¼ŒæŒ‡å®š Topic åç§°ï¼Œå¹¶ä¼˜åŒ–æ¶ˆæ¯è¿‡æ»¤è§„åˆ™ã€‚ éªŒè¯ï¼šæ£€æŸ¥ Maxwell å’Œ Kafka æ˜¯å¦æ­£å¸¸å·¥ä½œï¼Œç¡®è®¤æ¶ˆæ¯è¢«æ­£ç¡®æ¶ˆè´¹ã€‚ å¦‚éœ€è°ƒæ•´æ›´å¤šç»†èŠ‚ï¼Œä¾‹å¦‚æ¶ˆæ¯æ ¼å¼æˆ–è¿‡æ»¤ç‰¹å®šæ•°æ®è¡¨ï¼ŒMaxwell æä¾›çµæ´»çš„é€‰é¡¹æ”¯æŒã€‚\n","date": "2025-06-27 00:00:00",
    "updated": "2025-06-27 00:00:00"
  }, 
  {
    "objectID": "1751007600",
    "permalink": "/post/%E5%AE%9E%E6%97%B6%E9%87%87%E9%9B%86%E6%96%B9%E6%B3%95/",
    "title": "å®æ—¶é‡‡é›†çš„æ–¹æ³•","content": " 1. ä½¿ç”¨ Flume é‡‡é›†æŸç«¯å£çš„å®æ—¶æ•°æ®æµå¹¶å­˜å…¥ Kafka æŒ‡å®šçš„Topic ä¸­ flumeçš„é…ç½® a1.sources=r1 a1.sinks=k1 a1.channels=c1 a1.sources.r1.type=netcat a1.sources.r1.bind=master a1.sources.r1.port=9999 a1.sinks.k1.type=org.apache.flume.sink.kafka.KafkaSink a1.sinks.k1.brokerList=master:9092,slave1:9092,slave2:9092 a1.sinks.k1.topic=lol a1.sinks.k1.serializer.class=kafka.serializer.StringEncoding a1.sinks.kafka.producer.max.request.size=10240000 a1.channels.c1.type=memory a1.channels.c1.capacity=100000 a1.channels.c1.transactionCapacity=1000 a1.sources.r1.channels=c1 a1.sinks.k1.channel=c1 #å¦‚ä½•åš 1.å¯åŠ¨è‡ªå·±é…ç½®çš„flumeæ–‡ä»¶ 2.å¯åŠ¨kafka 3.é…ç½®kafkaä¸»é¢˜ 4.æ¶ˆè´¹kafka 2. ä½¿ç”¨ Maxwell é‡‡é›† MySQL çš„ binlog æ—¥å¿—å¹¶å­˜å…¥ Kafka æŒ‡å®šçš„Topic ä¸­ Maxwellçš„é…ç½® åœ¨Maxwellä¸­é…ç½®åˆ°config.propertiesæ–‡ä»¶ï¼ˆå¯èƒ½éœ€è¦è‡ªå·±åˆ›å»ºï¼‰\n# MySQL é…ç½® host=\u0026lt;MySQL ä¸»æœºåœ°å€\u0026gt; user=\u0026lt;MySQL ç”¨æˆ·å\u0026gt; password=\u0026lt;MySQL å¯†ç \u0026gt; port=3306 # Kafka é…ç½® producer=kafka kafka.bootstrap.servers=\u0026lt;Kafka é›†ç¾¤åœ°å€\u0026gt; kafka_topic=\u0026lt;Kafka Topic åç§°\u0026gt; ç¼–è¾‘Mysqlé…ç½® æ–‡ä»¶åœ°å€ vi /etc/my.cnf æˆ–/usr/local/mysql/my.cnf\n#ç¡®ä¿ MySQL å·²å¯ç”¨ binlog [mysqld] # å¯ç”¨ binlog log-bin=mysql-bin # è®¾ç½® binlog æ ¼å¼ä¸º ROWï¼ˆæ¨èï¼‰ binlog_format=row # è®¾ç½® server-idï¼ˆæ¯ä¸ª MySQL å®ä¾‹å¿…é¡»å”¯ä¸€ï¼‰ server-id=1 log-bin è¡¨ç¤ºå¯ç”¨ binlogã€‚ binlog_format=row è¡¨ç¤ºä½¿ç”¨è¡Œçº§åˆ«çš„ binlogï¼ˆMaxwell å¿…é¡»ä½¿ç”¨ row æ ¼å¼ï¼‰ã€‚ server-id å¿…é¡»è®¾ç½®ä¸”å”¯ä¸€ï¼Œå¦åˆ™æ— æ³•å¯ç”¨ binlogã€‚ #ä¸º Maxwell åˆ›å»ºä¸€ä¸ªå…·æœ‰è¯»å– binlog æƒé™çš„ç”¨æˆ· CREATE USER \u0026#39;maxwell\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;password\u0026#39;; GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO \u0026#39;maxwell\u0026#39;@\u0026#39;%\u0026#39;; FLUSH PRIVILEGES; éªŒè¯ éªŒè¯ Maxwell ç”¨æˆ·æƒé™æ˜¯å¦æ­£å¸¸ï¼š ä½¿ç”¨ maxwell ç”¨æˆ·è¿æ¥ MySQLï¼š mysql -u maxwell -p -h \u0026lt;MySQL ä¸»æœº\u0026gt; éªŒè¯æ˜¯å¦å¯ä»¥è¯»å– binlogï¼š SHOW MASTER STATUS; å¦‚æœèƒ½æ­£å¸¸è¿”å› binlog æ–‡ä»¶åå’Œä½ç½®ï¼Œåˆ™è¯´æ˜é…ç½®æˆåŠŸã€‚ #å¦‚ä½•åš å…ˆé…ç½®å¥½ä¸Šé¢ä¸¤ä¸ª æ³¨æ„é…ç½®å¥½mysqléœ€è¦é‡æ–°å¯åŠ¨ //å¯ä»¥æ£€éªŒä¸€ä¸‹æ˜¯mysqlæ˜¯å¦é…ç½®å¥½ 1.å¯åŠ¨kafka 2.åˆ›å»ºkafkaä¸»é¢˜ 3.å¯åŠ¨Maxwell 4.å¯åŠ¨kafkaçš„æ¶ˆè´¹è€… ","date": "2025-06-27 00:00:00",
    "updated": "2025-06-27 00:00:00"
  }, 
  {
    "objectID": "1715796000",
    "permalink": "/post/flink_kafka_job_guide.md/",
    "title": "Flume + Flink Kafka å®æ—¶å¤„ç†ä»»åŠ¡é…ç½®ä¸å¼€å‘","content": " ä¸€ã€Flume é‡‡é›†å™¨é…ç½® a1.sources=r1 a1.channels=c1 a1.sinks=k1 a1.sources.r1.type=netcat a1.sources.r1.bind=localhost a1.sources.r1.port=26001 a1.channels.c1.type=memory a1.channels.c1.capacity=1000 a1.channels.c1.transactionCapacity=100 a1.sinks.k1.type=org.apache.flume.sink.kafka.KafkaSink a1.sinks.k1.brokerList=master:9092,slave1:9092,slave2:9092 a1.sinks.k1.topic=tb_hhh a1.sinks.k1.serializer.class=kafka.serializer.StringEncoder a1.sources.r1.channels=c1 a1.sinks.k1.channel=c1 äºŒã€Flink ä»»åŠ¡å¼€å‘æ­¥éª¤ 1. æ„å»º Flink ç¯å¢ƒ val env = StreamExecutionEnvironment.getExecutionEnvironment env.setParallelism(1) ... inputStream.print() env.execute(\u0026#34;JobName\u0026#34;) 2. ç¡®è®¤æ•°æ®æ¥æº // æµ‹è¯•æ–‡ä»¶ val inputStream = env.readTextFile(\u0026#34;è·¯å¾„\u0026#34;) // ç½‘ç»œç«¯å£ val inputStream = env.socketTextStream(\u0026#34;localhost\u0026#34;, ç«¯å£å·) // Kafka val props = new Properties() props.setProperty(\u0026#34;bootstrap.servers\u0026#34;, \u0026#34;192.168.136.3:9092,...\u0026#34;) props.setProperty(\u0026#34;group.id\u0026#34;, \u0026#34;aaa\u0026#34;) val inputStream = env.addSource(new FlinkKafkaConsumer[String](\u0026#34;student_hhh\u0026#34;, new SimpleStringSchema(), props)) 3. æ•°æ®æ¸…æ´— val dataStream = inputStream.filter(x =\u0026gt; x.startsWith(\u0026#34;A\u0026#34;)) 4. æ•°æ®åˆ†ç»„ä¸èšåˆ val resultStream = dataStream.map(x =\u0026gt; { val arr1 = x.split(\u0026#34;åˆ†éš”ç¬¦\u0026#34;) val arr2 = arr1(1).split(\u0026#34;åˆ†éš”ç¬¦\u0026#34;) (arr2(0), 1) }).keyBy(_._1).sum(1) 5. æ—¶é—´çª—å£ï¼ˆå¯é€‰ï¼‰ .keyBy(_._1) .timeWindow(Time.minutes(8)) // æ»šåŠ¨çª—å£ .timeWindow(Time.minutes(10), Time.minutes(3)) // æ»‘åŠ¨çª—å£ 6. æ•°æ®è¾“å‡º (1) Redis å­—ç¬¦ä¸²å½¢å¼ val conf = new FlinkJedisPoolConfig.Builder().setHost(\u0026#34;localhost\u0026#34;).setPort(6379).build() dataStream.addSink(new RedisSink[String](conf, new RedisMapper[String] { override def getCommandDescription = new RedisCommandDescription(RedisCommand.SET) override def getKeyFromData(t: String): String = t._1 override def getValueFromData(t: String): String = t._2.toString })) (2) Redis å“ˆå¸Œå½¢å¼ new RedisCommandDescription(RedisCommand.HSET, \u0026#34;myKey\u0026#34;) (3) æ•°æ®å­˜å…¥ MySQL class MysqlSink extends RichSinkFunction[(String, Int)] { var conn: Connection = _ var upPstmt: PreparedStatement = _ var inPstmt: PreparedStatement = _ override def open(parameters: Configuration): Unit = { conn = DriverManager.getConnection(\u0026#34;jdbc:mysql://...\u0026#34;,\u0026#34;root\u0026#34;,\u0026#34;password\u0026#34;) inPstmt = conn.prepareStatement(\u0026#34;INSERT INTO tb_course_score VALUES (NULL,?,?)\u0026#34;) upPstmt = conn.prepareStatement(\u0026#34;UPDATE tb_course_score SET score=? WHERE course=?\u0026#34;) } override def invoke(value: (String, Int), context: SinkFunction.Context): Unit = { upPstmt.setInt(1, value._2) upPstmt.setString(2, value._1) upPstmt.execute() if (upPstmt.getUpdateCount == 0) { inPstmt.setString(1, value._1) inPstmt.setInt(2, value._2) inPstmt.execute() } } override def close(): Unit = { upPstmt.close() inPstmt.close() conn.close() } } (4) æ•°æ®å†™å…¥ ClickHouse class ClickHouseSink extends RichSinkFunction[(String,String,String,Double,String,String,String,String,String)] { var conn: Connection = _ var pstmt: PreparedStatement = _ override def open(parameters: Configuration): Unit = { conn = DriverManager.getConnection(\u0026#34;jdbc:clickhouse://182.168.136.3\u0026#34;,\u0026#34;default\u0026#34;,\u0026#34;123456\u0026#34;) pstmt = conn.prepareStatement(\u0026#34;INSERT INTO tb_hhh VALUES(?,?,?,?,?,?,?,?,?)\u0026#34;) } override def invoke(value: (String, String, String, Double, String, String, String, String, String), context: SinkFunction.Context): Unit = { pstmt.setString(1, value._1) pstmt.setString(2, value._2) pstmt.setString(3, value._3) pstmt.setDouble(4, value._4) pstmt.setString(5, value._5) pstmt.setString(6, value._6) pstmt.setString(7, value._7) pstmt.setString(8, value._8) pstmt.setString(9, value._9) pstmt.execute() } override def close(): Unit = { conn.close() pstmt.close() } } 7. æäº¤æ‰§è¡Œä»»åŠ¡ æ‰“åŒ…æ­¥éª¤ï¼š åœ¨ IntelliJ IDEA ä¸­æ„å»º -\u0026gt; Build Artifacts -\u0026gt; Rebuild JAR åŒ…è·¯å¾„ï¼šout/artifacts/...jar ä¼ è¾“è‡³æœåŠ¡å™¨ /opt/jars/ æ‰§è¡Œä»»åŠ¡ï¼š # Flink é›†ç¾¤æ–¹å¼ï¼ˆéœ€å…ˆç›‘å¬ç«¯å£ï¼‰ flink run -c com.xxx.MainClass /opt/jars/app.jar # Yarn æ–¹å¼ï¼ˆéœ€å¯åŠ¨ Hadoopï¼‰ flink run -m yarn-cluster -c com.xxx.MainClass /opt/jars/app.jar # å¦‚æœå‡ºé”™ï¼š export HADOOP_CLASSPATH=`hadoop classpath` è‡³æ­¤ï¼Œå®Œæ•´æ•°æ®é‡‡é›†ã€å¤„ç†ä¸å­˜å‚¨æµç¨‹å®Œæˆã€‚\n","date": "2024-05-15 11:00:00",
    "updated": "2024-05-15 11:00:00"
  }, 
  {
    "objectID": "1715796000",
    "permalink": "/post/vue_flask_guide/",
    "title": "Vueå‰ç«¯ + åç«¯ Flask æ„å»º","content": " ä¸€ã€å‰ç«¯æ„å»ºæ­¥éª¤ 1. å®‰è£… Node.js è®¿é—®å®˜ç½‘ä¸‹è½½å®‰è£…ï¼š https://nodejs.org/zh-cn/download ä¸‹è½½ Windows 64 ä½ .msi æ–‡ä»¶ï¼Œå®‰è£…æ—¶å»ºè®®ä¸è¦å®‰è£…åˆ° C ç›˜æˆ–å¸¦ä¸­æ–‡çš„ç›®å½•ã€‚ éªŒè¯å®‰è£…æ˜¯å¦æˆåŠŸï¼š\nnode -v npm -v 2. å‡çº§ç›¸å…³ä¾èµ– npm install express --registry=https://registry.npm.taobao.org npm install -g node npm install -g npm npm install -g cnpm --registry=https://registry.npm.taobao.org 3. å®‰è£… vue-cli è„šæ‰‹æ¶å·¥å…· npm install -g @vue/cli vue -V # æŸ¥çœ‹ç‰ˆæœ¬ï¼Œå¿…é¡»ä¸º 4.5.X ä»¥ä¸Š å¦‚éœ€å‡çº§ vue-cliï¼š\nnpm update -g @vue/cli å¸è½½å‘½ä»¤ï¼š\nnpm uninstall -g vue-cli 4. åˆ›å»º Vue3 é¡¹ç›® cd your_project_path # è¿›å…¥é¡¹ç›®ç›®å½•ï¼ˆæœ€å¥½ä½¿ç”¨è‹±æ–‡è·¯å¾„ï¼‰ vue create é¡¹ç›®å 5. å¯åŠ¨é¡¹ç›® cd é¡¹ç›®å npm run serve 6. ä½¿ç”¨ VSCode æ‰“å¼€é¡¹ç›®ï¼Œå‚è€ƒç½‘ä¸Š Vue é¡¹ç›®ç›®å½•ç»“æ„è¯´æ˜ äºŒã€åç«¯æœåŠ¡ç«¯æ„å»ºï¼ˆFlask + MySQLï¼‰ 1. å‡†å¤‡ç¯å¢ƒ å®‰è£… MySQL æ•°æ®åº“ å®‰è£… Python 3.7 å®‰è£… PyCharm ä¸“ä¸šç‰ˆ 2. åˆ›å»º Flask é¡¹ç›® æ‰“å¼€ PyCharmï¼Œæ–°å»ºé¡¹ç›® å·¦ä¾§é€‰æ‹© Flaskï¼ŒæŒ‡å®šé¡¹ç›®ç›®å½• 3. ç¼–è¾‘ app.py æ–‡ä»¶ï¼Œç²˜è´´å¦‚ä¸‹æœåŠ¡ç«¯ä»£ç ï¼š å¯¼å…¥ä¾èµ–ï¼š\nfrom flask import Flask, request import pymysql import json app = Flask(__name__) æ¥å£1ï¼šè·å–æ‰€æœ‰æ•°æ®\n@app.route(\u0026#39;/getBrowserByDate1\u0026#39;, methods=[\u0026#39;GET\u0026#39;]) def getBrowserByDate1(): conn = pymysql.connect(host=\u0026#39;127.0.0.1\u0026#39;, user=\u0026#39;root\u0026#39;, passwd=\u0026#39;123456\u0026#39;, db=\u0026#39;shtd_store\u0026#39;, charset=\u0026#39;utf8\u0026#39;) cur = conn.cursor() cur.execute(\u0026#34;SELECT * FROM tb_browsers\u0026#34;) res = cur.fetchall() cur.close() conn.commit() conn.close() arrayResult = [] for row in res: result = { \u0026#39;id\u0026#39;: row[0], \u0026#39;user\u0026#39;: row[1], \u0026#39;code\u0026#39;: row[2], \u0026#39;browser\u0026#39;: row[3], \u0026#39;banner\u0026#39;: row[4], \u0026#39;score_designer\u0026#39;: row[5], \u0026#39;score_speed\u0026#39;: row[6], \u0026#39;score_content\u0026#39;: row[7], \u0026#39;visit_date\u0026#39;: row[8] } arrayResult.append(result) result = { \u0026#39;code\u0026#39;: 200, \u0026#39;msg\u0026#39;: \u0026#39;æŸ¥è¯¢æˆåŠŸ\u0026#39;, \u0026#39;results\u0026#39;: arrayResult } return json.dumps(result).encode(\u0026#39;utf-8\u0026#39;).decode(\u0026#39;unicode_escape\u0026#39;) æ¥å£2ï¼šæŒ‰æ—¶é—´æ®µæŸ¥è¯¢æ•°æ®\n@app.route(\u0026#39;/getBrowserByDate2\u0026#39;, methods=[\u0026#39;POST\u0026#39;]) def getBrowserByDate2(): start = request.form.get(\u0026#39;start\u0026#39;) end = request.form.get(\u0026#39;end\u0026#39;) conn = pymysql.connect(host=\u0026#39;127.0.0.1\u0026#39;, user=\u0026#39;root\u0026#39;, passwd=\u0026#39;123456\u0026#39;, db=\u0026#39;shtd_store\u0026#39;, charset=\u0026#39;utf8\u0026#39;) cur = conn.cursor() cur.execute(\u0026#34;SELECT * FROM tb_browsers WHERE visit_date \u0026gt;= \u0026#39;{}\u0026#39; AND visit_date \u0026lt;= \u0026#39;{}\u0026#39;\u0026#34;.format(start, end)) res = cur.fetchall() cur.close() conn.commit() conn.close() arrayResult = [] for row in res: result = { \u0026#39;id\u0026#39;: row[0], \u0026#39;user\u0026#39;: row[1], \u0026#39;code\u0026#39;: row[2], \u0026#39;browser\u0026#39;: row[3], \u0026#39;banner\u0026#39;: row[4], \u0026#39;score_designer\u0026#39;: row[5], \u0026#39;score_speed\u0026#39;: row[6], \u0026#39;score_content\u0026#39;: row[7], \u0026#39;visit_date\u0026#39;: row[8] } arrayResult.append(result) result = { \u0026#39;code\u0026#39;: 200, \u0026#39;msg\u0026#39;: \u0026#39;æŸ¥è¯¢æˆåŠŸ\u0026#39;, \u0026#39;results\u0026#39;: arrayResult } return json.dumps(result).encode(\u0026#39;utf-8\u0026#39;).decode(\u0026#39;unicode_escape\u0026#39;) 4. ä¾èµ–å®‰è£… å¦‚æœå‡ºç° pymysql æˆ– json æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ä¾èµ–ï¼š\npip install PyMySQL -i https://pypi.tuna.tsinghua.edu.cn/simple è‡³æ­¤ï¼Œå‰åç«¯é¡¹ç›®æ­å»ºå®Œæ¯•ã€‚\n","date": "2024-05-15 11:00:00",
    "updated": "2024-05-15 11:00:00"
  }, 
  {
    "objectID": "1678903200",
    "permalink": "/post/flume_kafka_flink_pipeline/",
    "title": "Flume + Kafka + Flink å®æ—¶æ•°æ®å¤„ç†","content": " 1. Flume é‡‡é›†æ•°æ®è‡³ Kafka æ­¥éª¤ä¸€ï¼šé…ç½® Flume ç›‘å¬ 20000 ç«¯å£ï¼Œå°†æ•°æ®æ‰“å°åˆ°æ§åˆ¶å°æµ‹è¯• é…ç½®æ–‡ä»¶ mytest.conf å†…å®¹ï¼š\na1.sources=r1 a1.channels=c1 a1.sinks=k1 a1.sources.r1.type=netcat a1.sources.r1.bind=localhost a1.sources.r1.port=20000 a1.channels.c1.type=memory a1.sinks.k1.type=logger #a1.sinks.k1.type=org.apache.flume.sink.kafka.KafkaSink #a1.sinks.k1.kafka.topic=mytest #a1.sinks.k1.kafka.bootstrap.servers=192.168.44.201:9092,192.168.44.202:9092,192.168.44.203:9092 a1.sources.r1.channels=c1 a1.sinks.k1.channel=c1 å¯åŠ¨å‘½ä»¤ï¼š\nflume-ng agent -c conf -f mytest.conf --name a1 -Dflume.root.logger=INFO,console æ­¥éª¤äºŒï¼šKafka è®¾ç½® å¯åŠ¨ Zookeeperï¼šzkServer.sh start å¯åŠ¨ Kafkaï¼škafka-server-start.sh -daemon /usr/local/src/kafka/config/server.properties æŸ¥çœ‹ä¸»é¢˜ï¼škafka-topics.sh --zookeeper master:2181 --list åˆ›å»ºä¸»é¢˜ï¼š kafka-topics.sh --create --zookeeper master:2181 --replication-factor 1 --partitions 1 --topic mytest å¯åŠ¨ Kafka æ¶ˆè´¹è€…æŸ¥çœ‹æ•°æ®ï¼š kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mytest --from-beginning 2. Flink æ¶ˆè´¹ Kafka æ•°æ®å¹¶è¿›è¡Œè®¡ç®— éœ€æ±‚ï¼š æ¯åˆ†é’Ÿå†…å„ç”¨æˆ·æœ‰æ•ˆè®¢å•æ€»é¢å†™å…¥ MySQL æ¯åˆ†é’Ÿå†…æœ‰æ•ˆè®¢å•æ€»æ•°å†™å…¥ Redisï¼Œkey ä¸º total_orders Flink è‡ªå®šä¹‰ Sink å†™æ³•ï¼š class MySqlSink extends RichSinkFunction[(String, Double)] { var conn: Connection = _ var pstmt: PreparedStatement = _ override def open(parameters: Configuration): Unit = { conn = DriverManager.getConnection(\u0026#34;jdbc:mysql://192.168.6.86:3306/bike_db?characterEncoding=utf-8\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;123456\u0026#34;) pstmt = conn.prepareStatement(\u0026#34;INSERT INTO order_stats(user_id, total_amount) VALUES (?, ?)\u0026#34;) } override def invoke(value: (String, Double), context: SinkFunction.Context[_]): Unit = { pstmt.setString(1, value._1) pstmt.setDouble(2, value._2) pstmt.executeUpdate() } override def close(): Unit = { pstmt.close() conn.close() } } ä½¿ç”¨è‡ªå®šä¹‰ Sinkï¼š resultStream.addSink(new MySqlSink()) 3. Flink ç¨‹åºæäº¤æ–¹å¼ æ–¹å¼ä¸€ï¼šFlink é›†ç¾¤è¿è¡Œ flink run -c com.xxx.demo.XXXXDemo /opt/jars/xxxx.jar å¯é€šè¿‡ Flink Web UIï¼ˆé»˜è®¤ 8081ï¼‰æŸ¥çœ‹å’Œå–æ¶ˆä»»åŠ¡ æ–¹å¼äºŒï¼šFlink on Yarn è¿è¡Œ flink run -m yarn-cluster -c com.xxx.demo.XXXXDemo /opt/jars/xxxx.jar å¦‚æœæç¤º hadoop-classpath é”™è¯¯ï¼š export HADOOP_CLASSPATH=`hadoop classpath` åœæ­¢ä»»åŠ¡ï¼š yarn application -kill application_xxxxx æ³¨æ„äº‹é¡¹ å°†æä¾›çš„ä¾èµ–åŒ…æ”¾å…¥ flink/lib ä¸‹ é›†ç¾¤å…¶ä»–æœºå™¨ä¹Ÿè¦æ‹·è´ä¾èµ–åŒ… ","date": "2023-03-15 11:00:00",
    "updated": "2023-03-15 11:00:00"
  }, 
  {
    "objectID": "1678903200",
    "permalink": "/post/hello/",
    "title": "Hello World","content": "ğŸ’˜ åšéº— éœŠå¤¢ ğŸ’˜\n","date": "2023-03-15 11:00:00",
    "updated": "2023-03-15 11:00:00"
  }]